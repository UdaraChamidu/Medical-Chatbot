# ğŸ§  AI-Powered Medical Chatbot with Image & Symptom Analysis

![Python](https://img.shields.io/badge/Python-3.11-blue.svg)
![FastAPI](https://img.shields.io/badge/FastAPI-ğŸš€-green)
![Groq](https://img.shields.io/badge/Groq-API-red)

This medica chatbot is an AI powered web based medical chatbot that allows users to upload **medical images** and describe their symptoms. It then intelligently analyzes both inputs using Groq's Vision Language Models to provide **diagnoses, insights, and explanations**. This model is live @ huggingface.

---

## ğŸ” Features 

- ğŸ–¼ï¸ Upload retinal/OCT or other medical images
- ğŸ§¾ Enter symptoms or ask questions
- ğŸ§  Uses Groqâ€™s large multimodal language models to generate answers
- ğŸ” Secure API key management via `.env`
- ğŸ“¦ Built with FastAPI and Jinja2 templates
- âš¡ Clean, modular, and ready for deployment
- Deployed in huggingface.

---

## Try the Med Assistant
[![Open App](https://img.shields.io/badge/Open%20MedicalChatbot%20App-Click%20Here-brightgreen?style=for-the-badge)](https://huggingface.co/spaces/UdaraChamidu/Medical-Chatbot)


---

## ğŸ“¸ Screenshots 

<p align="center"> <img width="800" alt="Medical Chatbot Screenshot" src="https://github.com/user-attachments/assets/ba5a7de7-f495-4e9d-965d-128f931dca59" /> </p>

---

## ğŸ“„ Demo

> Upload a fundus image and ask:  
> _"What eye disease does this image indicate?"_  
>  

> Response (from LLaMA Vision):  
> _"The image suggests signs of diabetic retinopathy with scattered hemorrhages..."_

---

## ğŸ—ï¸ Project Structure

```
â”œâ”€â”€ main.py                 # FastAPI app (uses multiple models)                                          
â”œâ”€â”€ app.py                  # Slimmed version (uses one model)                                            
â”œâ”€â”€ templates/ index.html   # Frontend form                                              
â”œâ”€â”€ .env                    # API keys (not pushed to GitHub)                                           
â”œâ”€â”€ requirements.txt        # Dependencies                                                        
â””â”€â”€ README.md               # This file
```

---                                                         

## ğŸ“¤ How It Works

- Upload an image and type a query (symptoms or questions)
- The image is verified, converted to base64, and sent along with the query to Groqâ€™s API.
- The selected vision language model (meta-llama/llama-4-scout-17b-16e-instruct) analyzes both inputs.
- The response is displayed to the user.

---

## ğŸ› ï¸ Technologies Used

- FastAPI
- Groq API
- Pillow â€“ for image validation
- Requests
- dotenv - handle environment variables
- Docker
- Huggingface

---

## ğŸ§ª To Run

```
python -m venv venv
venv\Scripts\activate

pip install -r requirements.txt
python app.py
```
